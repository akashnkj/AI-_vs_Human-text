# Required Libraries 
import pandas as pd
import streamlit as st
import numpy as np
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from Features_pipeline import repetition_score, remove_punctuation,readability_score,typo_count,creativity_score,length_variance
from Features_pipeline import p_repetition_score, p_remove_punctuation,p_readability_score,p_typo_count,p_creativity_score,p_lenght_variance

# Title 
st.title('AI vs Human Text Generation Detector')

# Bot Introduction
st.write("""Is this text from a clever human or a cleverer machine?
This tool uses machine learning to analyze your input and predict whether it was written by an AI or a real person â€” and tells you why it thinks so""")

# Taking Input From User
text = st.text_input('Enter Your Text')

# load model and predict the text
loaded_model = joblib.load('XGBoost_Text_Classifier.pkl')
prediction = loaded_model.predict([[text]])
prob = loaded_model.predict_proba([[text]])
prob = int(max(prob[0])* 100) 

# Calcuating Results
len_var = p_lenght_variance(text)
read_scr = p_readability_score(text)
punct_fre_txt = p_remove_punctuation(text)
repetn_scr = p_repetition_score(punct_fre_txt)
creat_scr = p_creativity_score(punct_fre_txt)
spell_cnt = p_typo_count(punct_fre_txt)

# Preparing Results

Rationale = []

if 0 <= len_var <= 35:
    Rationale.append('There is a consistent structure across the sentences.') 
elif 35 < len_var <= 60:
    Rationale.append('The text contains a combination of medium-length and long sentences.')
elif len_var > 60:
    Rationale.append('The sentence lengths vary abruptly.')

if 0 <= repetn_scr <= 10:
    Rationale.append('Filler words are used appropriately.')
elif 10 < repetn_scr <= 15:
    Rationale.append('There is frequent repetition of filler words.')
elif repetn_scr > 15:
    Rationale.append('There is excessive use of filler words.')

if creat_scr >= 75:
    Rationale.append('The text uses a wide range of vocabulary.')
elif creat_scr < 70:
    Rationale.append('The language feels a bit plain.')

if read_scr > 60:
    Rationale.append('The writing is clear and straightforward.')
elif 20 <= read_scr <=60:
    Rationale.append('The text contains both complex and simple sentences.')
elif read_scr < 20:
    Rationale.append('The text is fairly complex.')

if prediction == 1:
    pred = 'AI-Generated'
else:
    pred = 'Human-Generated'


if pred == 'AI-Generated':
    conclusion = '            There is a high probability that the given text was generated by a AI.'
else:
    conclusion = '            There is a high probability that the given text was generated by a human.'


# Our Outputs

st.write('Classification Report :')
st.write(f'     - Origin         : {pred}, {prob}% Confidence')
st.write('     - Rationale      :',''.join(Rationale))
st.write()
st.write('Feature Report :')
st.write('     - Length Variance : ', np.round(len_var,2))
st.write('     - Repetition      : ', np.round(repetn_scr,2))
st.write('     - Typos           : ', np.round(spell_cnt,2))
st.write('     - Creativity      : ', np.round(creat_scr,2))
st.write('     - Readiability    : ', np.round(read_scr))
st.write()
st.write('Conclusion : ')
st.write(conclusion)